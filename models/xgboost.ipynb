{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b34fb3-99bb-495b-b8c8-7f44cb5580af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in ./venv/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.11/site-packages (from xgboost) (1.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061f436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mahdikhashan/tmp/tu-mlops'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c2c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.regressor import LowerBoundModel, HigherBoundModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5bc3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lower Bound Model...\n",
      "[0]\ttrain-rmse:2.40107\teval-rmse:2.29932\n",
      "[1]\ttrain-rmse:2.39476\teval-rmse:2.29351\n",
      "[2]\ttrain-rmse:2.38852\teval-rmse:2.28775\n",
      "[3]\ttrain-rmse:2.38235\teval-rmse:2.28206\n",
      "[4]\ttrain-rmse:2.37625\teval-rmse:2.27644\n",
      "[5]\ttrain-rmse:2.37023\teval-rmse:2.27088\n",
      "[6]\ttrain-rmse:2.36428\teval-rmse:2.26539\n",
      "[7]\ttrain-rmse:2.35839\teval-rmse:2.25996\n",
      "[8]\ttrain-rmse:2.35258\teval-rmse:2.25459\n",
      "[9]\ttrain-rmse:2.34683\teval-rmse:2.24928\n",
      "[10]\ttrain-rmse:2.34160\teval-rmse:2.24384\n",
      "[11]\ttrain-rmse:2.33598\teval-rmse:2.23865\n",
      "[12]\ttrain-rmse:2.32991\teval-rmse:2.23282\n",
      "[13]\ttrain-rmse:2.32392\teval-rmse:2.22706\n",
      "[14]\ttrain-rmse:2.31802\teval-rmse:2.22177\n",
      "[15]\ttrain-rmse:2.31216\teval-rmse:2.21614\n",
      "[16]\ttrain-rmse:2.30637\teval-rmse:2.21058\n",
      "[17]\ttrain-rmse:2.30078\teval-rmse:2.20556\n",
      "[18]\ttrain-rmse:2.29503\teval-rmse:2.20012\n",
      "[19]\ttrain-rmse:2.28935\teval-rmse:2.19474\n",
      "[20]\ttrain-rmse:2.28335\teval-rmse:2.18939\n",
      "[21]\ttrain-rmse:2.27781\teval-rmse:2.18414\n",
      "[22]\ttrain-rmse:2.27233\teval-rmse:2.17896\n",
      "[23]\ttrain-rmse:2.26692\teval-rmse:2.17383\n",
      "[24]\ttrain-rmse:2.26118\teval-rmse:2.16872\n",
      "[25]\ttrain-rmse:2.25589\teval-rmse:2.16372\n",
      "[26]\ttrain-rmse:2.25067\teval-rmse:2.15878\n",
      "[27]\ttrain-rmse:2.24511\teval-rmse:2.15383\n",
      "[28]\ttrain-rmse:2.24001\teval-rmse:2.14901\n",
      "[29]\ttrain-rmse:2.23497\teval-rmse:2.14425\n",
      "[30]\ttrain-rmse:2.22960\teval-rmse:2.13947\n",
      "[31]\ttrain-rmse:2.22468\teval-rmse:2.13483\n",
      "[32]\ttrain-rmse:2.22038\teval-rmse:2.13057\n",
      "[33]\ttrain-rmse:2.21614\teval-rmse:2.12636\n",
      "[34]\ttrain-rmse:2.21195\teval-rmse:2.12220\n",
      "[35]\ttrain-rmse:2.20780\teval-rmse:2.11808\n",
      "[36]\ttrain-rmse:2.20370\teval-rmse:2.11401\n",
      "[37]\ttrain-rmse:2.19965\teval-rmse:2.10998\n",
      "[38]\ttrain-rmse:2.19564\teval-rmse:2.10600\n",
      "[39]\ttrain-rmse:2.19168\teval-rmse:2.10206\n",
      "[40]\ttrain-rmse:2.18777\teval-rmse:2.09817\n",
      "[41]\ttrain-rmse:2.18390\teval-rmse:2.09431\n",
      "[42]\ttrain-rmse:2.18008\teval-rmse:2.09051\n",
      "[43]\ttrain-rmse:2.17645\teval-rmse:2.08686\n",
      "[44]\ttrain-rmse:2.17286\teval-rmse:2.08325\n",
      "[45]\ttrain-rmse:2.16931\teval-rmse:2.07968\n",
      "[46]\ttrain-rmse:2.16565\teval-rmse:2.07603\n",
      "[47]\ttrain-rmse:2.16217\teval-rmse:2.07253\n",
      "[48]\ttrain-rmse:2.15874\teval-rmse:2.06907\n",
      "[49]\ttrain-rmse:2.15520\teval-rmse:2.06554\n",
      "[50]\ttrain-rmse:2.15184\teval-rmse:2.06215\n",
      "[51]\ttrain-rmse:2.14852\teval-rmse:2.05880\n",
      "[52]\ttrain-rmse:2.14509\teval-rmse:2.05538\n",
      "[53]\ttrain-rmse:2.14184\teval-rmse:2.05210\n",
      "[54]\ttrain-rmse:2.13862\teval-rmse:2.04886\n",
      "[55]\ttrain-rmse:2.13531\teval-rmse:2.04555\n",
      "[56]\ttrain-rmse:2.13216\teval-rmse:2.04237\n",
      "[57]\ttrain-rmse:2.12905\teval-rmse:2.03923\n",
      "[58]\ttrain-rmse:2.12584\teval-rmse:2.03602\n",
      "[59]\ttrain-rmse:2.12280\teval-rmse:2.03294\n",
      "[60]\ttrain-rmse:2.11978\teval-rmse:2.02989\n",
      "[61]\ttrain-rmse:2.11619\teval-rmse:2.02609\n",
      "[62]\ttrain-rmse:2.11325\teval-rmse:2.02311\n",
      "[63]\ttrain-rmse:2.11034\teval-rmse:2.02017\n",
      "[64]\ttrain-rmse:2.10685\teval-rmse:2.01647\n",
      "[65]\ttrain-rmse:2.10401\teval-rmse:2.01360\n",
      "[66]\ttrain-rmse:2.10120\teval-rmse:2.01076\n",
      "[67]\ttrain-rmse:2.09781\teval-rmse:2.00717\n",
      "[68]\ttrain-rmse:2.09507\teval-rmse:2.00439\n",
      "[69]\ttrain-rmse:2.09187\teval-rmse:2.00157\n",
      "[70]\ttrain-rmse:2.08930\teval-rmse:1.99903\n",
      "[71]\ttrain-rmse:2.08666\teval-rmse:1.99626\n",
      "[72]\ttrain-rmse:2.08403\teval-rmse:1.99359\n",
      "[73]\ttrain-rmse:2.08143\teval-rmse:1.99096\n",
      "[74]\ttrain-rmse:2.07825\teval-rmse:1.98759\n",
      "[75]\ttrain-rmse:2.07571\teval-rmse:1.98501\n",
      "[76]\ttrain-rmse:2.07321\teval-rmse:1.98247\n",
      "[77]\ttrain-rmse:2.06999\teval-rmse:1.97919\n",
      "[78]\ttrain-rmse:2.06707\teval-rmse:1.97664\n",
      "[79]\ttrain-rmse:2.06480\teval-rmse:1.97431\n",
      "[80]\ttrain-rmse:2.06241\teval-rmse:1.97181\n",
      "[81]\ttrain-rmse:2.06004\teval-rmse:1.96940\n",
      "[82]\ttrain-rmse:2.05760\teval-rmse:1.96696\n",
      "[83]\ttrain-rmse:2.05466\teval-rmse:1.96385\n",
      "[84]\ttrain-rmse:2.05192\teval-rmse:1.96147\n",
      "[85]\ttrain-rmse:2.04978\teval-rmse:1.95927\n",
      "[86]\ttrain-rmse:2.04755\teval-rmse:1.95694\n",
      "[87]\ttrain-rmse:2.04534\teval-rmse:1.95468\n",
      "[88]\ttrain-rmse:2.04305\teval-rmse:1.95240\n",
      "[89]\ttrain-rmse:2.04026\teval-rmse:1.94945\n",
      "[90]\ttrain-rmse:2.03768\teval-rmse:1.94723\n",
      "[91]\ttrain-rmse:2.03568\teval-rmse:1.94516\n",
      "[92]\ttrain-rmse:2.03359\teval-rmse:1.94297\n",
      "[93]\ttrain-rmse:2.03152\teval-rmse:1.94086\n",
      "[94]\ttrain-rmse:2.02938\teval-rmse:1.93873\n",
      "[95]\ttrain-rmse:2.02692\teval-rmse:1.93662\n",
      "[96]\ttrain-rmse:2.02493\teval-rmse:1.93452\n",
      "[97]\ttrain-rmse:2.02302\teval-rmse:1.93256\n",
      "[98]\ttrain-rmse:2.02106\teval-rmse:1.93055\n",
      "[99]\ttrain-rmse:2.01851\teval-rmse:1.92785\n",
      "[100]\ttrain-rmse:2.01660\teval-rmse:1.92589\n",
      "[101]\ttrain-rmse:2.01471\teval-rmse:1.92396\n",
      "[102]\ttrain-rmse:2.01222\teval-rmse:1.92133\n",
      "[103]\ttrain-rmse:2.00996\teval-rmse:1.91940\n",
      "[104]\ttrain-rmse:2.00811\teval-rmse:1.91757\n",
      "[105]\ttrain-rmse:2.00631\teval-rmse:1.91568\n",
      "[106]\ttrain-rmse:2.00433\teval-rmse:1.91381\n",
      "[107]\ttrain-rmse:2.00258\teval-rmse:1.91219\n",
      "[108]\ttrain-rmse:1.99923\teval-rmse:1.90920\n",
      "[109]\ttrain-rmse:1.99753\teval-rmse:1.90761\n",
      "[110]\ttrain-rmse:1.99584\teval-rmse:1.90604\n",
      "[111]\ttrain-rmse:1.99257\teval-rmse:1.90313\n",
      "[112]\ttrain-rmse:1.99092\teval-rmse:1.90159\n",
      "[113]\ttrain-rmse:1.98930\teval-rmse:1.90008\n",
      "[114]\ttrain-rmse:1.98610\teval-rmse:1.89723\n",
      "[115]\ttrain-rmse:1.98451\teval-rmse:1.89575\n",
      "[116]\ttrain-rmse:1.98294\teval-rmse:1.89428\n",
      "[117]\ttrain-rmse:1.97982\teval-rmse:1.89150\n",
      "[118]\ttrain-rmse:1.97828\teval-rmse:1.89006\n",
      "[119]\ttrain-rmse:1.97676\teval-rmse:1.88864\n",
      "[120]\ttrain-rmse:1.97303\teval-rmse:1.88593\n",
      "[121]\ttrain-rmse:1.97109\teval-rmse:1.88399\n",
      "[122]\ttrain-rmse:1.96938\teval-rmse:1.88235\n",
      "[123]\ttrain-rmse:1.96685\teval-rmse:1.88032\n",
      "[124]\ttrain-rmse:1.96524\teval-rmse:1.87883\n",
      "[125]\ttrain-rmse:1.96365\teval-rmse:1.87735\n",
      "[126]\ttrain-rmse:1.96070\teval-rmse:1.87474\n",
      "[127]\ttrain-rmse:1.95930\teval-rmse:1.87342\n",
      "[128]\ttrain-rmse:1.95775\teval-rmse:1.87197\n",
      "[129]\ttrain-rmse:1.95489\teval-rmse:1.86945\n",
      "[130]\ttrain-rmse:1.95354\teval-rmse:1.86818\n",
      "[131]\ttrain-rmse:1.95221\teval-rmse:1.86692\n",
      "[132]\ttrain-rmse:1.94984\teval-rmse:1.86504\n",
      "[133]\ttrain-rmse:1.94835\teval-rmse:1.86364\n",
      "[134]\ttrain-rmse:1.94688\teval-rmse:1.86226\n",
      "[135]\ttrain-rmse:1.94405\teval-rmse:1.85975\n",
      "[136]\ttrain-rmse:1.94279\teval-rmse:1.85856\n",
      "[137]\ttrain-rmse:1.94135\teval-rmse:1.85721\n",
      "[138]\ttrain-rmse:1.93856\teval-rmse:1.85473\n",
      "[139]\ttrain-rmse:1.93735\teval-rmse:1.85358\n",
      "[140]\ttrain-rmse:1.93615\teval-rmse:1.85245\n",
      "[141]\ttrain-rmse:1.93394\teval-rmse:1.85069\n",
      "[142]\ttrain-rmse:1.93161\teval-rmse:1.84862\n",
      "[143]\ttrain-rmse:1.92883\teval-rmse:1.84620\n",
      "[144]\ttrain-rmse:1.92780\teval-rmse:1.84532\n",
      "[145]\ttrain-rmse:1.92564\teval-rmse:1.84346\n",
      "[146]\ttrain-rmse:1.92290\teval-rmse:1.84108\n",
      "[147]\ttrain-rmse:1.92190\teval-rmse:1.84023\n",
      "[148]\ttrain-rmse:1.92097\teval-rmse:1.83964\n",
      "[149]\ttrain-rmse:1.91963\teval-rmse:1.83851\n",
      "[150]\ttrain-rmse:1.91843\teval-rmse:1.83749\n",
      "[151]\ttrain-rmse:1.91724\teval-rmse:1.83648\n",
      "[152]\ttrain-rmse:1.91515\teval-rmse:1.83442\n",
      "[153]\ttrain-rmse:1.91437\teval-rmse:1.83360\n",
      "[154]\ttrain-rmse:1.91404\teval-rmse:1.83363\n",
      "[155]\ttrain-rmse:1.91401\teval-rmse:1.83361\n",
      "[156]\ttrain-rmse:1.91398\teval-rmse:1.83358\n",
      "[157]\ttrain-rmse:1.91395\teval-rmse:1.83356\n",
      "[158]\ttrain-rmse:1.91357\teval-rmse:1.83355\n",
      "[159]\ttrain-rmse:1.91319\teval-rmse:1.83353\n",
      "[160]\ttrain-rmse:1.91282\teval-rmse:1.83351\n",
      "[161]\ttrain-rmse:1.91245\teval-rmse:1.83349\n",
      "[162]\ttrain-rmse:1.91210\teval-rmse:1.83347\n",
      "[163]\ttrain-rmse:1.91175\teval-rmse:1.83345\n",
      "[164]\ttrain-rmse:1.91140\teval-rmse:1.83343\n",
      "[165]\ttrain-rmse:1.91124\teval-rmse:1.83315\n",
      "[166]\ttrain-rmse:1.91090\teval-rmse:1.83313\n",
      "[167]\ttrain-rmse:1.91057\teval-rmse:1.83311\n",
      "[168]\ttrain-rmse:1.91025\teval-rmse:1.83309\n",
      "[169]\ttrain-rmse:1.90993\teval-rmse:1.83308\n",
      "[170]\ttrain-rmse:1.90962\teval-rmse:1.83306\n",
      "[171]\ttrain-rmse:1.90931\teval-rmse:1.83304\n",
      "[172]\ttrain-rmse:1.90901\teval-rmse:1.83302\n",
      "[173]\ttrain-rmse:1.90872\teval-rmse:1.83301\n",
      "[174]\ttrain-rmse:1.90843\teval-rmse:1.83299\n",
      "[175]\ttrain-rmse:1.90795\teval-rmse:1.83277\n",
      "[176]\ttrain-rmse:1.90713\teval-rmse:1.83234\n",
      "[177]\ttrain-rmse:1.90623\teval-rmse:1.83139\n",
      "[178]\ttrain-rmse:1.90502\teval-rmse:1.83045\n",
      "[179]\ttrain-rmse:1.90382\teval-rmse:1.82963\n",
      "[180]\ttrain-rmse:1.90348\teval-rmse:1.82933\n",
      "[181]\ttrain-rmse:1.90304\teval-rmse:1.82914\n",
      "[182]\ttrain-rmse:1.90206\teval-rmse:1.82797\n",
      "[183]\ttrain-rmse:1.90164\teval-rmse:1.82779\n",
      "[184]\ttrain-rmse:1.90122\teval-rmse:1.82761\n",
      "[185]\ttrain-rmse:1.90008\teval-rmse:1.82671\n",
      "[186]\ttrain-rmse:1.89905\teval-rmse:1.82559\n",
      "[187]\ttrain-rmse:1.89797\teval-rmse:1.82494\n",
      "[188]\ttrain-rmse:1.89703\teval-rmse:1.82402\n",
      "[189]\ttrain-rmse:1.89617\teval-rmse:1.82328\n",
      "[190]\ttrain-rmse:1.89532\teval-rmse:1.82254\n",
      "[191]\ttrain-rmse:1.89429\teval-rmse:1.82143\n",
      "[192]\ttrain-rmse:1.89394\teval-rmse:1.82116\n",
      "[193]\ttrain-rmse:1.89357\teval-rmse:1.82102\n",
      "[194]\ttrain-rmse:1.89249\teval-rmse:1.82020\n",
      "[195]\ttrain-rmse:1.89148\teval-rmse:1.81960\n",
      "[196]\ttrain-rmse:1.88969\teval-rmse:1.81772\n",
      "[197]\ttrain-rmse:1.88875\teval-rmse:1.81716\n",
      "[198]\ttrain-rmse:1.88804\teval-rmse:1.81637\n",
      "[199]\ttrain-rmse:1.88720\teval-rmse:1.81573\n",
      "\n",
      "Training Higher Bound Model...\n",
      "[0]\ttrain-rmse:2.61121\teval-rmse:2.48343\n",
      "[1]\ttrain-rmse:2.60276\teval-rmse:2.47587\n",
      "[2]\ttrain-rmse:2.59442\teval-rmse:2.46841\n",
      "[3]\ttrain-rmse:2.58616\teval-rmse:2.46103\n",
      "[4]\ttrain-rmse:2.57801\teval-rmse:2.45374\n",
      "[5]\ttrain-rmse:2.57113\teval-rmse:2.44922\n",
      "[6]\ttrain-rmse:2.56421\teval-rmse:2.44492\n",
      "[7]\ttrain-rmse:2.55736\teval-rmse:2.44070\n",
      "[8]\ttrain-rmse:2.54952\teval-rmse:2.43366\n",
      "[9]\ttrain-rmse:2.54292\teval-rmse:2.42938\n",
      "[10]\ttrain-rmse:2.53628\teval-rmse:2.42532\n",
      "[11]\ttrain-rmse:2.52971\teval-rmse:2.42133\n",
      "[12]\ttrain-rmse:2.52217\teval-rmse:2.41454\n",
      "[13]\ttrain-rmse:2.51583\teval-rmse:2.41049\n",
      "[14]\ttrain-rmse:2.50946\teval-rmse:2.40665\n",
      "[15]\ttrain-rmse:2.50316\teval-rmse:2.40287\n",
      "[16]\ttrain-rmse:2.49590\teval-rmse:2.39632\n",
      "[17]\ttrain-rmse:2.48982\teval-rmse:2.39248\n",
      "[18]\ttrain-rmse:2.48371\teval-rmse:2.38885\n",
      "[19]\ttrain-rmse:2.47766\teval-rmse:2.38527\n",
      "[20]\ttrain-rmse:2.47068\teval-rmse:2.37896\n",
      "[21]\ttrain-rmse:2.46484\teval-rmse:2.37532\n",
      "[22]\ttrain-rmse:2.45897\teval-rmse:2.37188\n",
      "[23]\ttrain-rmse:2.45317\teval-rmse:2.36850\n",
      "[24]\ttrain-rmse:2.44645\teval-rmse:2.36240\n",
      "[25]\ttrain-rmse:2.44084\teval-rmse:2.35895\n",
      "[26]\ttrain-rmse:2.43521\teval-rmse:2.35570\n",
      "[27]\ttrain-rmse:2.42964\teval-rmse:2.35250\n",
      "[28]\ttrain-rmse:2.42317\teval-rmse:2.34662\n",
      "[29]\ttrain-rmse:2.41779\teval-rmse:2.34334\n",
      "[30]\ttrain-rmse:2.41238\teval-rmse:2.34026\n",
      "[31]\ttrain-rmse:2.40703\teval-rmse:2.33723\n",
      "[32]\ttrain-rmse:2.40080\teval-rmse:2.33156\n",
      "[33]\ttrain-rmse:2.39563\teval-rmse:2.32845\n",
      "[34]\ttrain-rmse:2.39044\teval-rmse:2.32553\n",
      "[35]\ttrain-rmse:2.38531\teval-rmse:2.32266\n",
      "[36]\ttrain-rmse:2.37930\teval-rmse:2.31718\n",
      "[37]\ttrain-rmse:2.37434\teval-rmse:2.31423\n",
      "[38]\ttrain-rmse:2.36935\teval-rmse:2.31147\n",
      "[39]\ttrain-rmse:2.36442\teval-rmse:2.30874\n",
      "[40]\ttrain-rmse:2.35864\teval-rmse:2.30346\n",
      "[41]\ttrain-rmse:2.35463\teval-rmse:2.30001\n",
      "[42]\ttrain-rmse:2.35067\teval-rmse:2.29660\n",
      "[43]\ttrain-rmse:2.34676\teval-rmse:2.29323\n",
      "[44]\ttrain-rmse:2.34115\teval-rmse:2.28811\n",
      "[45]\ttrain-rmse:2.33688\teval-rmse:2.28561\n",
      "[46]\ttrain-rmse:2.33309\teval-rmse:2.28235\n",
      "[47]\ttrain-rmse:2.32933\teval-rmse:2.27912\n",
      "[48]\ttrain-rmse:2.32433\teval-rmse:2.27461\n",
      "[49]\ttrain-rmse:2.31997\teval-rmse:2.27208\n",
      "[50]\ttrain-rmse:2.31557\teval-rmse:2.26968\n",
      "[51]\ttrain-rmse:2.31123\teval-rmse:2.26527\n",
      "[52]\ttrain-rmse:2.30725\teval-rmse:2.26161\n",
      "[53]\ttrain-rmse:2.30272\teval-rmse:2.25758\n",
      "[54]\ttrain-rmse:2.29859\teval-rmse:2.25520\n",
      "[55]\ttrain-rmse:2.29468\teval-rmse:2.25124\n",
      "[56]\ttrain-rmse:2.29085\teval-rmse:2.24771\n",
      "[57]\ttrain-rmse:2.28710\teval-rmse:2.24555\n",
      "[58]\ttrain-rmse:2.28425\teval-rmse:2.24274\n",
      "[59]\ttrain-rmse:2.28050\teval-rmse:2.23927\n",
      "[60]\ttrain-rmse:2.27621\teval-rmse:2.23547\n",
      "[61]\ttrain-rmse:2.27261\teval-rmse:2.23340\n",
      "[62]\ttrain-rmse:2.26895\teval-rmse:2.23001\n",
      "[63]\ttrain-rmse:2.26626\teval-rmse:2.22734\n",
      "[64]\ttrain-rmse:2.26263\teval-rmse:2.22364\n",
      "[65]\ttrain-rmse:2.25671\teval-rmse:2.21769\n",
      "[66]\ttrain-rmse:2.25262\teval-rmse:2.21407\n",
      "[67]\ttrain-rmse:2.24883\teval-rmse:2.21198\n",
      "[68]\ttrain-rmse:2.24510\teval-rmse:2.20815\n",
      "[69]\ttrain-rmse:2.24086\teval-rmse:2.20415\n",
      "[70]\ttrain-rmse:2.23759\teval-rmse:2.20228\n",
      "[71]\ttrain-rmse:2.23521\teval-rmse:2.19991\n",
      "[72]\ttrain-rmse:2.23109\teval-rmse:2.19540\n",
      "[73]\ttrain-rmse:2.22790\teval-rmse:2.19358\n",
      "[74]\ttrain-rmse:2.22381\teval-rmse:2.18970\n",
      "[75]\ttrain-rmse:2.22155\teval-rmse:2.18745\n",
      "[76]\ttrain-rmse:2.21847\teval-rmse:2.18569\n",
      "[77]\ttrain-rmse:2.21528\teval-rmse:2.18270\n",
      "[78]\ttrain-rmse:2.21155\teval-rmse:2.17942\n",
      "[79]\ttrain-rmse:2.20848\teval-rmse:2.17638\n",
      "[80]\ttrain-rmse:2.20552\teval-rmse:2.17469\n",
      "[81]\ttrain-rmse:2.20243\teval-rmse:2.17179\n",
      "[82]\ttrain-rmse:2.19882\teval-rmse:2.16862\n",
      "[83]\ttrain-rmse:2.19353\teval-rmse:2.16325\n",
      "[84]\ttrain-rmse:2.19048\teval-rmse:2.16150\n",
      "[85]\ttrain-rmse:2.18669\teval-rmse:2.15812\n",
      "[86]\ttrain-rmse:2.18296\teval-rmse:2.15456\n",
      "[87]\ttrain-rmse:2.18020\teval-rmse:2.15298\n",
      "[88]\ttrain-rmse:2.17830\teval-rmse:2.15107\n",
      "[89]\ttrain-rmse:2.17472\teval-rmse:2.14715\n",
      "[90]\ttrain-rmse:2.17205\teval-rmse:2.14562\n",
      "[91]\ttrain-rmse:2.16844\teval-rmse:2.14216\n",
      "[92]\ttrain-rmse:2.16663\teval-rmse:2.14036\n",
      "[93]\ttrain-rmse:2.16402\teval-rmse:2.13886\n",
      "[94]\ttrain-rmse:2.16126\teval-rmse:2.13625\n",
      "[95]\ttrain-rmse:2.15851\teval-rmse:2.13339\n",
      "[96]\ttrain-rmse:2.15362\teval-rmse:2.12841\n",
      "[97]\ttrain-rmse:2.15011\teval-rmse:2.12530\n",
      "[98]\ttrain-rmse:2.14803\teval-rmse:2.12350\n",
      "[99]\ttrain-rmse:2.14465\teval-rmse:2.12025\n",
      "[100]\ttrain-rmse:2.14207\teval-rmse:2.11758\n",
      "[101]\ttrain-rmse:2.13963\teval-rmse:2.11616\n",
      "[102]\ttrain-rmse:2.13632\teval-rmse:2.11297\n",
      "[103]\ttrain-rmse:2.13481\teval-rmse:2.11146\n",
      "[104]\ttrain-rmse:2.13232\teval-rmse:2.10886\n",
      "[105]\ttrain-rmse:2.12995\teval-rmse:2.10748\n",
      "[106]\ttrain-rmse:2.12739\teval-rmse:2.10503\n",
      "[107]\ttrain-rmse:2.12453\teval-rmse:2.10251\n",
      "[108]\ttrain-rmse:2.12287\teval-rmse:2.10080\n",
      "[109]\ttrain-rmse:2.11820\teval-rmse:2.09614\n",
      "[110]\ttrain-rmse:2.11507\teval-rmse:2.09331\n",
      "[111]\ttrain-rmse:2.11351\teval-rmse:2.09170\n",
      "[112]\ttrain-rmse:2.10906\teval-rmse:2.08715\n",
      "[113]\ttrain-rmse:2.10599\teval-rmse:2.08419\n",
      "[114]\ttrain-rmse:2.10312\teval-rmse:2.08188\n",
      "[115]\ttrain-rmse:2.09891\teval-rmse:2.07802\n",
      "[116]\ttrain-rmse:2.09611\teval-rmse:2.07577\n",
      "[117]\ttrain-rmse:2.09506\teval-rmse:2.07479\n",
      "[118]\ttrain-rmse:2.09313\teval-rmse:2.07265\n",
      "[119]\ttrain-rmse:2.09153\teval-rmse:2.07122\n",
      "[120]\ttrain-rmse:2.08918\teval-rmse:2.06927\n",
      "[121]\ttrain-rmse:2.08626\teval-rmse:2.06698\n",
      "[122]\ttrain-rmse:2.08221\teval-rmse:2.06327\n",
      "[123]\ttrain-rmse:2.07958\teval-rmse:2.06116\n",
      "[124]\ttrain-rmse:2.07869\teval-rmse:2.06033\n",
      "[125]\ttrain-rmse:2.07781\teval-rmse:2.05951\n",
      "[126]\ttrain-rmse:2.07636\teval-rmse:2.05823\n",
      "[127]\ttrain-rmse:2.07117\teval-rmse:2.05326\n",
      "[128]\ttrain-rmse:2.07036\teval-rmse:2.05251\n",
      "[129]\ttrain-rmse:2.06957\teval-rmse:2.05178\n",
      "[130]\ttrain-rmse:2.06752\teval-rmse:2.04978\n",
      "[131]\ttrain-rmse:2.06491\teval-rmse:2.04787\n",
      "[132]\ttrain-rmse:2.06017\teval-rmse:2.04380\n",
      "[133]\ttrain-rmse:2.05775\teval-rmse:2.04187\n",
      "[134]\ttrain-rmse:2.05706\teval-rmse:2.04124\n",
      "[135]\ttrain-rmse:2.05582\teval-rmse:2.04015\n",
      "[136]\ttrain-rmse:2.05208\teval-rmse:2.03670\n",
      "[137]\ttrain-rmse:2.04973\teval-rmse:2.03484\n",
      "[138]\ttrain-rmse:2.04912\teval-rmse:2.03427\n",
      "[139]\ttrain-rmse:2.04681\teval-rmse:2.03243\n",
      "[140]\ttrain-rmse:2.04315\teval-rmse:2.02906\n",
      "[141]\ttrain-rmse:2.04089\teval-rmse:2.02727\n",
      "[142]\ttrain-rmse:2.04035\teval-rmse:2.02677\n",
      "[143]\ttrain-rmse:2.03980\teval-rmse:2.02627\n",
      "[144]\ttrain-rmse:2.03621\teval-rmse:2.02296\n",
      "[145]\ttrain-rmse:2.03403\teval-rmse:2.02122\n",
      "[146]\ttrain-rmse:2.03352\teval-rmse:2.02076\n",
      "[147]\ttrain-rmse:2.03303\teval-rmse:2.02030\n",
      "[148]\ttrain-rmse:2.03253\teval-rmse:2.01985\n",
      "[149]\ttrain-rmse:2.02847\teval-rmse:2.01616\n",
      "[150]\ttrain-rmse:2.02693\teval-rmse:2.01482\n",
      "[151]\ttrain-rmse:2.02503\teval-rmse:2.01324\n",
      "[152]\ttrain-rmse:2.02257\teval-rmse:2.01130\n",
      "[153]\ttrain-rmse:2.01824\teval-rmse:2.00755\n",
      "[154]\ttrain-rmse:2.01623\teval-rmse:2.00597\n",
      "[155]\ttrain-rmse:2.01585\teval-rmse:2.00562\n",
      "[156]\ttrain-rmse:2.01547\teval-rmse:2.00528\n",
      "[157]\ttrain-rmse:2.01510\teval-rmse:2.00493\n",
      "[158]\ttrain-rmse:2.01354\teval-rmse:2.00341\n",
      "[159]\ttrain-rmse:2.01148\teval-rmse:2.00196\n",
      "[160]\ttrain-rmse:2.00725\teval-rmse:1.99829\n",
      "[161]\ttrain-rmse:2.00535\teval-rmse:1.99680\n",
      "[162]\ttrain-rmse:2.00404\teval-rmse:1.99598\n",
      "[163]\ttrain-rmse:2.00321\teval-rmse:1.99527\n",
      "[164]\ttrain-rmse:1.99906\teval-rmse:1.99167\n",
      "[165]\ttrain-rmse:1.99636\teval-rmse:1.98937\n",
      "[166]\ttrain-rmse:1.99425\teval-rmse:1.98725\n",
      "[167]\ttrain-rmse:1.99197\teval-rmse:1.98542\n",
      "[168]\ttrain-rmse:1.99045\teval-rmse:1.98322\n",
      "[169]\ttrain-rmse:1.98885\teval-rmse:1.98201\n",
      "[170]\ttrain-rmse:1.98418\teval-rmse:1.97701\n",
      "[171]\ttrain-rmse:1.97933\teval-rmse:1.97352\n",
      "[172]\ttrain-rmse:1.97563\teval-rmse:1.97015\n",
      "[173]\ttrain-rmse:1.96827\teval-rmse:1.96434\n",
      "[174]\ttrain-rmse:1.96659\teval-rmse:1.96276\n",
      "[175]\ttrain-rmse:1.96201\teval-rmse:1.95863\n",
      "[176]\ttrain-rmse:1.95988\teval-rmse:1.95684\n",
      "[177]\ttrain-rmse:1.95652\teval-rmse:1.95400\n",
      "[178]\ttrain-rmse:1.95532\teval-rmse:1.95277\n",
      "[179]\ttrain-rmse:1.95413\teval-rmse:1.95156\n",
      "[180]\ttrain-rmse:1.95203\teval-rmse:1.94904\n",
      "[181]\ttrain-rmse:1.95173\teval-rmse:1.94880\n",
      "[182]\ttrain-rmse:1.95158\teval-rmse:1.94870\n",
      "[183]\ttrain-rmse:1.95143\teval-rmse:1.94861\n",
      "[184]\ttrain-rmse:1.95127\teval-rmse:1.94851\n",
      "[185]\ttrain-rmse:1.95112\teval-rmse:1.94842\n",
      "[186]\ttrain-rmse:1.95098\teval-rmse:1.94833\n",
      "[187]\ttrain-rmse:1.95083\teval-rmse:1.94824\n",
      "[188]\ttrain-rmse:1.95068\teval-rmse:1.94815\n",
      "[189]\ttrain-rmse:1.95054\teval-rmse:1.94806\n",
      "[190]\ttrain-rmse:1.95040\teval-rmse:1.94797\n",
      "[191]\ttrain-rmse:1.95026\teval-rmse:1.94788\n",
      "[192]\ttrain-rmse:1.95012\teval-rmse:1.94780\n",
      "[193]\ttrain-rmse:1.94999\teval-rmse:1.94771\n",
      "[194]\ttrain-rmse:1.94985\teval-rmse:1.94763\n",
      "[195]\ttrain-rmse:1.94972\teval-rmse:1.94754\n",
      "[196]\ttrain-rmse:1.94959\teval-rmse:1.94746\n",
      "[197]\ttrain-rmse:1.94946\teval-rmse:1.94738\n",
      "[198]\ttrain-rmse:1.94933\teval-rmse:1.94730\n",
      "[199]\ttrain-rmse:1.94920\teval-rmse:1.94722\n",
      "\n",
      "Lower Bound Model RMSE: 1.8157\n",
      "Higher Bound Model RMSE: 1.9472\n",
      "Validation Set Coverage (Target: 0.80): 0.8000\n",
      "Average Prediction Interval Width: 2.9106\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 100\n",
    "n_features = 5\n",
    "\n",
    "X = np.random.rand(n_samples, n_features)\n",
    "true_coeffs = np.array([1.5, -2.5, 3.0, -1.0, 2.0])\n",
    "y = X.dot(true_coeffs) + np.random.normal(0, 0.5, n_samples) # Increased noise slightly\n",
    "\n",
    "# Using train_test_split is generally better\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "config = {\n",
    "    \"num_boost_round\": 200, # Increased rounds slightly\n",
    "    \"early_stopping_rounds\": 10\n",
    "}\n",
    "\n",
    "lower_bound_model = LowerBoundModel()\n",
    "higher_bound_model = HigherBoundModel()\n",
    "\n",
    "print(\"Training Lower Bound Model...\")\n",
    "lower_bound_model.train(X_train, y_train, X_val, y_val, config)\n",
    "print(\"\\nTraining Higher Bound Model...\")\n",
    "higher_bound_model.train(X_train, y_train, X_val, y_val, config)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Use corrected variable names\n",
    "lower_bound_rmse = lower_bound_model.evaluate(X_val, y_val, rmse)\n",
    "higher_bound_rmse = higher_bound_model.evaluate(X_val, y_val, rmse)\n",
    "\n",
    "print(f\"\\nLower Bound Model RMSE: {lower_bound_rmse:.4f}\")\n",
    "print(f\"Higher Bound Model RMSE: {higher_bound_rmse:.4f}\")\n",
    "\n",
    "# Optional: Check coverage on validation set\n",
    "lower_preds = lower_bound_model.predict(X_val)\n",
    "higher_preds = higher_bound_model.predict(X_val)\n",
    "coverage = np.mean((y_val >= lower_preds) & (y_val <= higher_preds))\n",
    "print(f\"Validation Set Coverage (Target: {0.9 - 0.1:.2f}): {coverage:.4f}\")\n",
    "avg_interval_width = np.mean(higher_preds - lower_preds)\n",
    "print(f\"Average Prediction Interval Width: {avg_interval_width:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d233b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
